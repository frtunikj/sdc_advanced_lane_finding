{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Lane Lines - Perspective transformation\n",
    "\n",
    "In this notebook the following points from the Project 4 Advanced Lane Lines are implemented:\n",
    "* Generating output video.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 0: Import required libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "\n",
    "from camera_calibration import undistortImage, calibrateCamera\n",
    "from color_gradient import imageTransformation\n",
    "from perspective_transformation import getPerspectiveTransform, warpImage2birdsEyeView\n",
    "from lane_detection import Line, window, getLaneIndices, getLanePixelPositions, detectLaneLines, projectLaneLinesRoad, calculateAndWriteCurvatureRadius, caculateAndWriteLaneOffset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2:  Track lane lines function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trackLaneLines(birdsEyeView, line_left, line_right):\n",
    "    nonzero = birdsEyeView.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    \n",
    "    out_img = (np.dstack((birdsEyeView, birdsEyeView, birdsEyeView))*255).astype(np.uint8)\n",
    "            \n",
    "    margin = 100  # dict_config_params['x_margin']\n",
    "        \n",
    "    left_fit = line_left.getFit(useAverageFit=True)\n",
    "    right_fit = line_right.getFit(useAverageFit=True)\n",
    "    \n",
    "    x_left = left_fit[0] * (nonzeroy**2) + left_fit[1] * nonzeroy + left_fit[2]\n",
    "    x_right = right_fit[0] * (nonzeroy**2) + right_fit[1] * nonzeroy + right_fit[2]\n",
    "        \n",
    "    w_left = window(x_left - margin, x_left + margin, nonzeroy.min(), nonzeroy.max()) \n",
    "    w_right = window(x_right - margin, x_right + margin, nonzeroy.min(), nonzeroy.max()) \n",
    "    \n",
    "    left_lane_inds, right_lane_inds = getLaneIndices(nonzero, w_left, w_right)\n",
    "    \n",
    "    pixel_pos_x, pixel_pos_y = getLanePixelPositions(nonzero, left_lane_inds)\n",
    "    line_left.updateLineFit(pixel_pos_x, pixel_pos_y)\n",
    "    \n",
    "    pixel_pos_x, pixel_pos_y = getLanePixelPositions(nonzero, right_lane_inds)\n",
    "    line_right.updateLineFit(pixel_pos_x, pixel_pos_y)\n",
    " \n",
    "    ploty, left_fitx = line_left.getXY(birdsEyeView.shape[0], useAverageFit=True)\n",
    "    ploty, right_fitx = line_right.getXY(birdsEyeView.shape[0], useAverageFit=True)\n",
    "    \n",
    "    # Color lane-pixels\n",
    "    out_img[nonzeroy[left_lane_inds], nonzerox[left_lane_inds]] = [255, 0, 0]\n",
    "    out_img[nonzeroy[right_lane_inds], nonzerox[right_lane_inds]] = [0, 0, 255]\n",
    "    \n",
    "    ## Draw search windows for the left and right lane lines\n",
    "    window_img = np.zeros_like(out_img)\n",
    "    \n",
    "    # Generate a polygon to illustrate the search window area\n",
    "    # And recast the x and y points into usable format for cv2.fillPoly()\n",
    "    left_window_left_line = np.array([np.transpose(np.vstack([left_fitx-margin, ploty]))])\n",
    "    left_window_right_line = np.array([np.flipud(np.transpose(np.vstack([left_fitx+margin, \n",
    "                                  ploty])))])\n",
    "    left_window_pts = np.hstack((left_window_left_line, left_window_right_line))\n",
    "    \n",
    "    right_window_left_line = np.array([np.transpose(np.vstack([right_fitx-margin, ploty]))])\n",
    "    right_window_right_line = np.array([np.flipud(np.transpose(np.vstack([right_fitx+margin, \n",
    "                                  ploty])))])\n",
    "    right_window_pts = np.hstack((right_window_left_line, right_window_right_line))\n",
    "    \n",
    "    # Draw the lane onto the warped blank image\n",
    "    cv2.fillPoly(window_img, np.int_([left_window_pts]), (0,255, 0))\n",
    "    cv2.fillPoly(window_img, np.int_([right_window_pts]), (0,255, 0))\n",
    "    out_img = cv2.addWeighted(out_img, 1, window_img, 0.3, 0)\n",
    "\n",
    "    return out_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3:  Initialize variables containing camera calibration and prespective transformation parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize():\n",
    "    # Calibrate camera\n",
    "    mtx, dist = calibrateCamera(useCalibrationCache=True)\n",
    "    \n",
    "    # Perspective transform\n",
    "    image = cv2.cvtColor(cv2.imread('./test_images/test2.jpg'), cv2.COLOR_BGR2RGB)\n",
    "    imageUndistored = undistortImage(image, mtx, dist, plotImages=False)\n",
    "    imageSize = (imageUndistored.shape[1], imageUndistored.shape[0])\n",
    "    src, dst, perspective_M, perspective_M_inv = getPerspectiveTransform(imageSize)\n",
    "    \n",
    "    return mtx, dist, perspective_M, perspective_M_inv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4:  Helper function processing video images/frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the `inputVideo` image by image/frame by frame to find the lane lines, draw curvarute and vehicle position information \n",
    "\n",
    "def processVideoImage(image):\n",
    "    global configParams\n",
    "    global numberImagesProcessed    \n",
    "    global mtx, dist, perspective_M, perspective_M_inv\n",
    "    global leftFit, rightFit, leftFitx, rightFitx \n",
    "    \n",
    "    undistoredImage = undistortImage(image, mtx, dist, plotImages=False)\n",
    "    imageTransformed = imageTransformation(undistoredImage)\n",
    "    \n",
    "    imageSize = (imageTransformed.shape[1], imageTransformed.shape[0])\n",
    "    birdsEyeView = warpImage2birdsEyeView(imageTransformed.astype(np.uint8), \n",
    "                                   imageSize, perspective_M).astype(bool)\n",
    "    \n",
    "    out_img = None\n",
    "    ploty = None\n",
    "    if numberImagesProcessed==0:        \n",
    "        outputImage = detectLaneLines(birdsEyeView, lineLeft, lineRight, plotImage=False)         \n",
    "    else:        \n",
    "        outputImage = trackLaneLines(birdsEyeView, lineLeft, lineRight)\n",
    "    \n",
    "    numberImagesProcessed += 1\n",
    "        \n",
    "    imageLinesRoad = projectLaneLinesRoad(undistoredImage, outputImage, lineLeft, lineRight, perspective_M_inv)\n",
    "    calculateAndWriteCurvatureRadius(imageLinesRoad, configParams, lineLeft, lineRight)\n",
    "    caculateAndWriteLaneOffset(imageLinesRoad, configParams, lineLeft, lineRight)\n",
    "        \n",
    "    return imageLinesRoad\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5:  Process and generate output video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using already available cached calibration results.\n",
      "\n",
      "[MoviePy] >>>> Building video output_project_video.mp4\n",
      "[MoviePy] Writing video output_project_video.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 1260/1261 [12:09<00:00,  1.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: output_project_video.mp4 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Config parameters\n",
    "configParams = {'x_margin': 100,\n",
    "                'y_meter_per_pixel': 30.0/720,\n",
    "                'x_meter_per_pixel': 3.7/700,\n",
    "                }\n",
    "\n",
    "leftFit, rightFit, leftFitx, rightFitx = None, None, None, None\n",
    "mtx, dist, perspective_M, perspective_M_inv = None, None, None, None\n",
    "lineLeft = None\n",
    "lineRight = None\n",
    "\n",
    "# Reset global\n",
    "numberImagesProcessed = 0\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    mtx, dist, perspective_M, perspective_M_inv = initialize()\n",
    "    \n",
    "    lineLeft = Line()\n",
    "    lineRight = Line()\n",
    "\n",
    "    #clip1 = VideoFileClip(\"./videos/project_video.mp4\").subclip(0,2)\n",
    "    #clip = clip1.fl_image(processVideoImage)\n",
    "    #clip.write_videofile(\"output_project_video_short.mp4\", audio=False)\n",
    "    \n",
    "    clip1 = VideoFileClip(\"./videos/project_video.mp4\")\n",
    "    clip = clip1.fl_image(processVideoImage)\n",
    "    clip.write_videofile(\"output_project_video.mp4\", audio=False)\n",
    "    \n",
    "    # Reset global\n",
    "    numberImagesProcessed = 0 "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
