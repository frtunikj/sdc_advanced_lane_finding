{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Lane Lines - Perspective transformation\n",
    "\n",
    "In this notebook the following points from the Project 4 Advanced Lane Lines are implemented:\n",
    "* Generating output video.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 0: Import required libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "\n",
    "from camera_calibration import undistortImage, calibrateCamera\n",
    "from color_gradient import imageTransformation\n",
    "from perspective_transformation import getPerspectiveTransform, warpImage2birdsEyeView, pipelineImageTransformation\n",
    "from lane_detection import Line, window, getLaneIndices, getLanePixelPositions, detectLaneLines, projectLaneLinesRoad, calculateAndWriteCurvatureRadius, caculateAndWriteLaneOffset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2:  Track lane lines function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trackLaneLines(birdsEyeView, line_left, line_right):\n",
    "    nonzero = birdsEyeView.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    \n",
    "    out_img = (np.dstack((birdsEyeView, birdsEyeView, birdsEyeView))*255).astype(np.uint8)\n",
    "            \n",
    "    margin = 100  # dict_config_params['x_margin']\n",
    "        \n",
    "    left_fit = line_left.getFit(useAverageFit=True)\n",
    "    right_fit = line_right.getFit(useAverageFit=True)\n",
    "    \n",
    "    x_left = left_fit[0] * (nonzeroy**2) + left_fit[1] * nonzeroy + left_fit[2]\n",
    "    x_right = right_fit[0] * (nonzeroy**2) + right_fit[1] * nonzeroy + right_fit[2]\n",
    "        \n",
    "    w_left = window(x_left - margin, x_left + margin, nonzeroy.min(), nonzeroy.max()) \n",
    "    w_right = window(x_right - margin, x_right + margin, nonzeroy.min(), nonzeroy.max()) \n",
    "    \n",
    "    left_lane_inds, right_lane_inds = getLaneIndices(nonzero, w_left, w_right)\n",
    "    \n",
    "    pixel_pos_x, pixel_pos_y = getLanePixelPositions(nonzero, left_lane_inds)\n",
    "    line_left.updateLineFit(pixel_pos_x, pixel_pos_y)\n",
    "    \n",
    "    pixel_pos_x, pixel_pos_y = getLanePixelPositions(nonzero, right_lane_inds)\n",
    "    line_right.updateLineFit(pixel_pos_x, pixel_pos_y)\n",
    " \n",
    "    ploty, left_fitx = line_left.getXY(birdsEyeView.shape[0], useAverageFit=True)\n",
    "    ploty, right_fitx = line_right.getXY(birdsEyeView.shape[0], useAverageFit=True)\n",
    "    \n",
    "    # Color lane-pixels\n",
    "    out_img[nonzeroy[left_lane_inds], nonzerox[left_lane_inds]] = [255, 0, 0]\n",
    "    out_img[nonzeroy[right_lane_inds], nonzerox[right_lane_inds]] = [0, 0, 255]\n",
    "    \n",
    "    ## Draw search windows for the left and right lane lines\n",
    "    window_img = np.zeros_like(out_img)\n",
    "    \n",
    "    # Generate a polygon to illustrate the search window area\n",
    "    # And recast the x and y points into usable format for cv2.fillPoly()\n",
    "    left_window_left_line = np.array([np.transpose(np.vstack([left_fitx-margin, ploty]))])\n",
    "    left_window_right_line = np.array([np.flipud(np.transpose(np.vstack([left_fitx+margin, \n",
    "                                  ploty])))])\n",
    "    left_window_pts = np.hstack((left_window_left_line, left_window_right_line))\n",
    "    \n",
    "    right_window_left_line = np.array([np.transpose(np.vstack([right_fitx-margin, ploty]))])\n",
    "    right_window_right_line = np.array([np.flipud(np.transpose(np.vstack([right_fitx+margin, \n",
    "                                  ploty])))])\n",
    "    right_window_pts = np.hstack((right_window_left_line, right_window_right_line))\n",
    "    \n",
    "    # Draw the lane onto the warped blank image\n",
    "    cv2.fillPoly(window_img, np.int_([left_window_pts]), (0,255, 0))\n",
    "    cv2.fillPoly(window_img, np.int_([right_window_pts]), (0,255, 0))\n",
    "    out_img = cv2.addWeighted(out_img, 1, window_img, 0.3, 0)\n",
    "\n",
    "    return out_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3:  Initialize variables containing camera calibration and prespective transformation parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize():\n",
    "    # Calibrate camera\n",
    "    mtx, dist = calibrateCamera(useCalibrationCache=True)\n",
    "    \n",
    "    # Perspective transform\n",
    "    image = cv2.cvtColor(cv2.imread('./test_images/test2.jpg'), cv2.COLOR_BGR2RGB)\n",
    "    imageUndistored = undistortImage(image, mtx, dist, plotImages=False)\n",
    "    imageSize = (imageUndistored.shape[1], imageUndistored.shape[0])\n",
    "    src, dst, perspective_M, perspective_M_inv = getPerspectiveTransform(imageSize)\n",
    "    \n",
    "    return mtx, dist, perspective_M, perspective_M_inv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4:  Helper function processing video images/frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the `inputVideo` image by image/frame by frame to find the lane lines, draw curvarute and vehicle position information \n",
    "\n",
    "def processVideoImage(image):\n",
    "    global configParams\n",
    "    global numberImagesProcessed    \n",
    "    global mtx, dist, perspective_M, perspective_M_inv\n",
    "    global leftFit, rightFit, leftFitx, rightFitx \n",
    "    \n",
    "    #undistoredImage = undistortImage(image, mtx, dist, plotImages=False)\n",
    "    #imageTransformed = imageTransformation(undistoredImage)\n",
    "    \n",
    "    #imageSize = (imageTransformed.shape[1], imageTransformed.shape[0])\n",
    "    #birdsEyeView = warpImage2birdsEyeView(imageTransformed.astype(np.uint8), \n",
    "                                   #imageSize, perspective_M).astype(bool)\n",
    "    \n",
    "    undistoredImage = undistortImage(image, mtx, dist, plotImages=False)\n",
    "    birdsEyeView = pipelineImageTransformation(image).astype(bool)\n",
    "\n",
    "    out_img = None\n",
    "    ploty = None\n",
    "    if numberImagesProcessed==0:        \n",
    "        outputImage = detectLaneLines(birdsEyeView, lineLeft, lineRight, plotImage=False)         \n",
    "    else:        \n",
    "        outputImage = trackLaneLines(birdsEyeView, lineLeft, lineRight)\n",
    "    \n",
    "    numberImagesProcessed += 1\n",
    "        \n",
    "    imageLinesRoad = projectLaneLinesRoad(undistoredImage, outputImage, lineLeft, lineRight, perspective_M_inv)\n",
    "    calculateAndWriteCurvatureRadius(imageLinesRoad, configParams, lineLeft, lineRight)\n",
    "    caculateAndWriteLaneOffset(imageLinesRoad, configParams, lineLeft, lineRight)\n",
    "        \n",
    "    return imageLinesRoad\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5:  Process and generate output video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using already available cached calibration results.\n",
      "\n",
      "[MoviePy] >>>> Building video output_project_video_short.mp4\n",
      "[MoviePy] Writing video output_project_video_short.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/51 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 1/51 [00:00<00:17,  2.88it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 2/51 [00:01<00:23,  2.08it/s]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▌         | 3/51 [00:01<00:22,  2.17it/s]\u001b[A\u001b[A\n",
      "\n",
      "  8%|▊         | 4/51 [00:01<00:19,  2.40it/s]\u001b[A\u001b[A\n",
      "\n",
      " 10%|▉         | 5/51 [00:02<00:17,  2.61it/s]\u001b[A\u001b[A\n",
      "\n",
      " 12%|█▏        | 6/51 [00:02<00:16,  2.72it/s]\u001b[A\u001b[A\n",
      "\n",
      " 14%|█▎        | 7/51 [00:02<00:15,  2.75it/s]\u001b[A\u001b[A\n",
      "\n",
      " 16%|█▌        | 8/51 [00:03<00:15,  2.79it/s]\u001b[A\u001b[A\n",
      "\n",
      " 18%|█▊        | 9/51 [00:03<00:15,  2.74it/s]\u001b[A\u001b[A\n",
      "\n",
      " 20%|█▉        | 10/51 [00:03<00:14,  2.78it/s]\u001b[A\u001b[A\n",
      "\n",
      " 22%|██▏       | 11/51 [00:04<00:14,  2.82it/s]\u001b[A\u001b[A\n",
      "\n",
      " 24%|██▎       | 12/51 [00:04<00:13,  2.89it/s]\u001b[A\u001b[A\n",
      "\n",
      " 25%|██▌       | 13/51 [00:05<00:14,  2.66it/s]\u001b[A\u001b[A\n",
      "\n",
      " 27%|██▋       | 14/51 [00:05<00:17,  2.15it/s]\u001b[A\u001b[A\n",
      "\n",
      " 29%|██▉       | 15/51 [00:06<00:17,  2.03it/s]\u001b[A\u001b[A\n",
      "\n",
      " 31%|███▏      | 16/51 [00:06<00:16,  2.17it/s]\u001b[A\u001b[A\n",
      "\n",
      " 33%|███▎      | 17/51 [00:07<00:14,  2.33it/s]\u001b[A\u001b[A\n",
      "\n",
      " 35%|███▌      | 18/51 [00:07<00:13,  2.44it/s]\u001b[A\u001b[A\n",
      "\n",
      " 37%|███▋      | 19/51 [00:07<00:12,  2.55it/s]\u001b[A\u001b[A\n",
      "\n",
      " 39%|███▉      | 20/51 [00:08<00:12,  2.49it/s]\u001b[A\u001b[A\n",
      "\n",
      " 41%|████      | 21/51 [00:08<00:11,  2.62it/s]\u001b[A\u001b[A\n",
      "\n",
      " 43%|████▎     | 22/51 [00:08<00:11,  2.62it/s]\u001b[A\u001b[A\n",
      "\n",
      " 45%|████▌     | 23/51 [00:09<00:10,  2.74it/s]\u001b[A\u001b[A\n",
      "\n",
      " 47%|████▋     | 24/51 [00:09<00:09,  2.88it/s]\u001b[A\u001b[A\n",
      "\n",
      " 49%|████▉     | 25/51 [00:09<00:08,  2.92it/s]\u001b[A\u001b[A\n",
      "\n",
      " 51%|█████     | 26/51 [00:10<00:09,  2.60it/s]\u001b[A\u001b[A\n",
      "\n",
      " 53%|█████▎    | 27/51 [00:10<00:09,  2.56it/s]\u001b[A\u001b[A\n",
      "\n",
      " 55%|█████▍    | 28/51 [00:11<00:08,  2.64it/s]\u001b[A\u001b[A\n",
      "\n",
      " 57%|█████▋    | 29/51 [00:11<00:08,  2.46it/s]\u001b[A\u001b[A\n",
      "\n",
      " 59%|█████▉    | 30/51 [00:12<00:08,  2.37it/s]\u001b[A\u001b[A\n",
      "\n",
      " 61%|██████    | 31/51 [00:12<00:09,  2.13it/s]\u001b[A\u001b[A\n",
      "\n",
      " 63%|██████▎   | 32/51 [00:13<00:08,  2.17it/s]\u001b[A\u001b[A\n",
      "\n",
      " 65%|██████▍   | 33/51 [00:13<00:07,  2.34it/s]\u001b[A\u001b[A\n",
      "\n",
      " 67%|██████▋   | 34/51 [00:13<00:07,  2.43it/s]\u001b[A\u001b[A\n",
      "\n",
      " 69%|██████▊   | 35/51 [00:14<00:06,  2.52it/s]\u001b[A\u001b[A\n",
      "\n",
      " 71%|███████   | 36/51 [00:14<00:05,  2.62it/s]\u001b[A\u001b[A\n",
      "\n",
      " 73%|███████▎  | 37/51 [00:14<00:05,  2.38it/s]\u001b[A\u001b[A\n",
      "\n",
      " 75%|███████▍  | 38/51 [00:15<00:05,  2.36it/s]\u001b[A\u001b[A\n",
      "\n",
      " 76%|███████▋  | 39/51 [00:15<00:04,  2.51it/s]\u001b[A\u001b[A\n",
      "\n",
      " 78%|███████▊  | 40/51 [00:16<00:04,  2.66it/s]\u001b[A\u001b[A\n",
      "\n",
      " 80%|████████  | 41/51 [00:16<00:03,  2.78it/s]\u001b[A\u001b[A\n",
      "\n",
      " 82%|████████▏ | 42/51 [00:16<00:03,  2.80it/s]\u001b[A\u001b[A\n",
      "\n",
      " 84%|████████▍ | 43/51 [00:17<00:03,  2.19it/s]\u001b[A\u001b[A\n",
      "\n",
      " 86%|████████▋ | 44/51 [00:18<00:04,  1.69it/s]\u001b[A\u001b[A\n",
      "\n",
      " 88%|████████▊ | 45/51 [00:18<00:03,  1.86it/s]\u001b[A\u001b[A\n",
      "\n",
      " 90%|█████████ | 46/51 [00:19<00:02,  2.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 92%|█████████▏| 47/51 [00:19<00:01,  2.22it/s]\u001b[A\u001b[A\n",
      "\n",
      " 94%|█████████▍| 48/51 [00:19<00:01,  2.22it/s]\u001b[A\u001b[A\n",
      "\n",
      " 96%|█████████▌| 49/51 [00:20<00:00,  2.19it/s]\u001b[A\u001b[A\n",
      "\n",
      " 98%|█████████▊| 50/51 [00:20<00:00,  2.35it/s]\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: output_project_video_short.mp4 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Config parameters\n",
    "configParams = {'x_margin': 100,\n",
    "                'y_meter_per_pixel': 30.0/720,\n",
    "                'x_meter_per_pixel': 3.7/700,\n",
    "                }\n",
    "\n",
    "leftFit, rightFit, leftFitx, rightFitx = None, None, None, None\n",
    "mtx, dist, perspective_M, perspective_M_inv = None, None, None, None\n",
    "lineLeft = None\n",
    "lineRight = None\n",
    "\n",
    "# Reset global\n",
    "numberImagesProcessed = 0\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    mtx, dist, perspective_M, perspective_M_inv = initialize()\n",
    "    \n",
    "    lineLeft = Line()\n",
    "    lineRight = Line()\n",
    "\n",
    "    #clip1 = VideoFileClip(\"./videos/project_video.mp4\").subclip(0,2)\n",
    "    #clip = clip1.fl_image(processVideoImage)\n",
    "    #clip.write_videofile(\"output_project_video_short.mp4\", audio=False)\n",
    "    \n",
    "    clip1 = VideoFileClip(\"./videos/project_video.mp4\")\n",
    "    clip = clip1.fl_image(processVideoImage)\n",
    "    clip.write_videofile(\"output_project_video.mp4\", audio=False)\n",
    "    \n",
    "    #clip1 = VideoFileClip(\"./videos/challenge_video.mp4\")\n",
    "    #clip = clip1.fl_image(processVideoImage)\n",
    "    #clip.write_videofile(\"output_challenge_video.mp4\", audio=False)\n",
    "    \n",
    "    # Reset global\n",
    "    numberImagesProcessed = 0 "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
